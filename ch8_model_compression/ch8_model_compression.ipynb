{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b54a61-5c2d-4f25-b475-9d7c5d0f8733",
   "metadata": {},
   "source": [
    "## 8.1 의도 탐지 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928e1915-833c-454c-b812-df4ed9f1dd81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (3.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: colorlog in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (2.0.17)\n",
      "Requirement already satisfied: tqdm in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1762b458-c761-4654-882f-c19b42283bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296b2003-904d-4c61-a24c-b876870be151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'car_rental', 'score': 0.5490034818649292}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in \n",
    "Paris and I need a 15 passenger van\"\"\"\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fced22-616c-4429-9bbf-bdace3ce2fbd",
   "metadata": {},
   "source": [
    "## 8.2 벤치마크 클래스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918f5130-78b6-41cd-b4c4-af0f434aebff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\"):\n",
    "        self.pipeline = pipeline\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "        \n",
    "    def compute_accuracy(self):\n",
    "        # 나중에 정의합니다\n",
    "        pass    \n",
    "\n",
    "    def compute_size(self):\n",
    "        # 나중에 정의합니다\n",
    "        pass\n",
    "\n",
    "    def time_pipeline(self):\n",
    "        # 나중에 정의합니다\n",
    "        pass\n",
    "    \n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type].update(self.time_pipeline())\n",
    "        metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b86866-76a6-4414-9e88-ccc846cc5fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset clinc_oos (/Users/daniellee/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ff1df2c69a487e90c0e0ff88aa9d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "clinc = load_dataset(\"clinc_oos\", \"plus\")  # \"plus\" 범위 박의 훈련 샘플이 담긴 서브셋을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e150ca7d-01df-4070-af03-0f722a4db567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'transfer $100 from my checking to saving account', 'intent': 133}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = clinc[\"test\"][42]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06caed5-de0b-483b-a42b-22aa73cf5938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transfer'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents = clinc[\"test\"].features[\"intent\"]\n",
    "intents.int2str(sample[\"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cef9066-31dd-41b2-a794-16e43c79d822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/rtsz9nj93kdd9vy3_52zngfc0000gn/T/ipykernel_10254/1330793347.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_score = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric \n",
    "\n",
    "accuracy_score = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd6e67b-ef8d-40d0-a293-b7e5829e7d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(self):\n",
    "    \"\"\"PerformanceBenchmark.compute_accuracy() 메서드를 오버라이드합니다\"\"\"\n",
    "    preds, labels = [], []\n",
    "    for example in self.dataset:\n",
    "        pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
    "        label = example[\"intent\"]\n",
    "        preds.append(intents.str2int(pred))\n",
    "        labels.append(label)\n",
    "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
    "    print(f\"테스트 세트 정확도 - {accuracy['accuracy']:.3f}\")\n",
    "    return accuracy\n",
    "\n",
    "PerformanceBenchmark.compute_accuracy = compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20471c98-9f7b-439f-b9d7-c7702957e163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert.encoder.layer.2.attention.self.value.weight',\n",
       " tensor([[-1.0526e-02, -3.2215e-02,  2.2097e-02,  ..., -6.0953e-03,\n",
       "           4.6521e-03,  2.9844e-02],\n",
       "         [-1.4964e-02, -1.0915e-02,  5.2396e-04,  ...,  3.2047e-05,\n",
       "          -2.6890e-02, -2.1943e-02],\n",
       "         [-2.9640e-02, -3.7842e-03, -1.2582e-02,  ..., -1.0917e-02,\n",
       "           3.1152e-02, -9.7786e-03],\n",
       "         ...,\n",
       "         [-1.5116e-02, -3.3226e-02,  4.2063e-02,  ..., -5.2652e-03,\n",
       "           1.1093e-02,  2.9703e-03],\n",
       "         [-3.6809e-02,  5.6848e-02, -2.6544e-02,  ..., -4.0114e-02,\n",
       "           6.7487e-03,  1.0511e-03],\n",
       "         [-2.4961e-02,  1.4747e-03, -5.4271e-02,  ...,  2.0004e-02,\n",
       "           2.3981e-02, -4.2880e-02]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipe.model.state_dict().items())[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20e9beba-7a5f-467e-9c12-9fa0dd09b37f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(pipe.model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64baa922-935f-4550-9284-9b47fe8c1a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_size(self):\n",
    "    \"\"\"PerformanceBenchmark.compute_size() 메서드를 오버라이드합니다\"\"\"\n",
    "    state_dict = self.pipeline.model.state_dict()\n",
    "    tmp_path = Path(\"model.pt\")\n",
    "    torch.save(state_dict, tmp_path)\n",
    "    # 메가바이트 단위로 크기를 계산합니다\n",
    "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "    # 임시 파일을 삭제합니다\n",
    "    tmp_path.unlink()\n",
    "    print(f\"모델 크기 (MB) - {size_mb:.2f}\")\n",
    "    return {\"size_mb\": size_mb}\n",
    "\n",
    "PerformanceBenchmark.compute_size = compute_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d088a9b2-4405-43da-a5b9-4025eaebcc45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이턴시 (ms) - 42.810\n",
      "레이턴시 (ms) - 37.233\n",
      "레이턴시 (ms) - 48.231\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "for _ in range(3):\n",
    "    start_time = perf_counter()\n",
    "    _ = pipe(query)\n",
    "    latency = perf_counter() - start_time\n",
    "    print(f\"레이턴시 (ms) - {1000 * latency:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaee5bae-4d42-4ab9-8da7-5d702c2f97f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
    "    \"\"\"PerformanceBenchmark.time_pipeline() 메서드를 오버라이드합니다d\"\"\"\n",
    "    latencies = []\n",
    "    # 워밍업\n",
    "    for _ in range(10):\n",
    "        _ = self.pipeline(query)\n",
    "    # 실행 측정\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ = self.pipeline(query)\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # 통게 계산\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    print(f\"평균 레이턴시 (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "PerformanceBenchmark.time_pipeline = time_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b70b6b-4549-4fd3-8daa-06cf6b5aec60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 크기 (MB) - 418.15\n",
      "평균 레이턴시 (ms) - 35.78 +\\- 0.79\n",
      "테스트 세트 정확도 - 0.867\n"
     ]
    }
   ],
   "source": [
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"])\n",
    "perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b24954da-568f-45fd-bc18-0980a347ec88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ff944df-ef8b-409e-9120-f3140c2670de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher_model = teacher_model\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        outputs_stu = model(**inputs)\n",
    "        # 스튜던트의 크로스 엔트로피 손실과 로짓을 추출합니다\n",
    "        loss_ce = outputs_stu.loss\n",
    "        logits_stu = outputs_stu.logits\n",
    "        # 티처의 로짓을 추출합니다\n",
    "        with torch.no_grad():\n",
    "            outputs_tea = self.teacher_model(**inputs)\n",
    "            logits_tea = outputs_tea.logits\n",
    "        # 확률을 부드럽게하고 정제 손실을 계산합니다\n",
    "        loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        loss_kd = self.args.temperature ** 2 * loss_fct(\n",
    "            F.log_softmax(logits_stu / self.args.temperature, dim=-1),\n",
    "            F.softmax(logits_tea / self.args.temperature, dim=-1))\n",
    "        # 가중 평균된 스튜던트 손실을 반환합니다\n",
    "        loss = self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd\n",
    "        return (loss, outputs_stu) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4823fb7d-ab6b-44ac-987e-8419f4aa2ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/daniellee/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1/cache-fea0c49e7fa93460.arrow\n",
      "Loading cached processed dataset at /Users/daniellee/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1/cache-7fecf478efcd7d09.arrow\n",
      "Loading cached processed dataset at /Users/daniellee/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1/cache-5bc73521e2f625e6.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "student_ckpt = \"distilbert-base-uncased\"\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)\n",
    "\n",
    "def tokenize_text(batch):\n",
    "    return student_tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"])\n",
    "clinc_enc = clinc_enc.rename_column(\"intent\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a19e817b-297c-4ca8-a118-d95197ad8685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()\n",
    "# jupyter notebook에서 안될때는 jupyter-lab이 실행중인 경로에서 \"huggingface-cli login\" 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e8f7b27-6f07-4337-a65b-7acd1b07906e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_score.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f3f587a-e497-48ab-9660-33476de70baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "\n",
    "finetuned_ckpt = \"distilbert-base-uncased-finetuned-clinc\"\n",
    "student_training_args = DistillationTrainingArguments(\n",
    "    output_dir=finetuned_ckpt, evaluation_strategy = \"epoch\", \n",
    "    num_train_epochs=5, learning_rate=2e-5, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, alpha=1, weight_decay=0.01, \n",
    "    push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36ee5c09-53a2-4173-9e1c-2c125a9d0ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_training_args.logging_steps = len(clinc_enc['train']) // batch_size\n",
    "student_training_args.disable_tqdm = False\n",
    "student_training_args.save_steps = 1e9\n",
    "# 트랜스포머 4.23.0 버전부터 로깅 수준을 문자열로 지정해야 합니다.\n",
    "# student_training_args.log_level = 40\n",
    "student_training_args.log_level = 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a3bba8f-a951-49cd-85c7-0e050c8ea63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10c2adfb-f3d7-45fa-81d5-c083039f7c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = pipe.model.config.id2label\n",
    "label2id = pipe.model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60a055cf-28f3-4e2f-9c40-29c192577612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "num_labels = intents.num_classes\n",
    "student_config = (AutoConfig\n",
    "                  .from_pretrained(student_ckpt, num_labels=num_labels, \n",
    "                                   id2label=id2label, label2id=label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7de2126-52fb-43f5-98cf-fb5461541d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def student_init():\n",
    "    return (AutoModelForSequenceClassification\n",
    "            .from_pretrained(student_ckpt, config=student_config).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ed9de4b-002d-4cba-a620-7a9194b02b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "teacher_model = (AutoModelForSequenceClassification\n",
    "                 .from_pretrained(teacher_ckpt, num_labels=num_labels)\n",
    "                 .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f534c298-0485-4753-98d4-48b47f985670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniellee/Develop/study_huggingface/ch8_model_compression/distilbert-base-uncased-finetuned-clinc is already a clone of https://huggingface.co/hexists/distilbert-base-uncased-finetuned-clinc. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1590/1590 33:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.283800</td>\n",
       "      <td>3.278687</td>\n",
       "      <td>0.745484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.622000</td>\n",
       "      <td>1.870629</td>\n",
       "      <td>0.833226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.546600</td>\n",
       "      <td>1.162256</td>\n",
       "      <td>0.893871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.013500</td>\n",
       "      <td>0.861896</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>0.778602</td>\n",
       "      <td>0.915806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1590, training_loss=2.0490037549216793, metrics={'train_runtime': 2022.314, 'train_samples_per_second': 37.704, 'train_steps_per_second': 0.786, 'total_flos': 413896353421488.0, 'train_loss': 2.0490037549216793, 'epoch': 5.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer = DistillationTrainer(model_init=student_init,\n",
    "    teacher_model=teacher_model, args=student_training_args,\n",
    "    train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'],\n",
    "    compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae7b25ef-db09-4229-89de-52da655bbf58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651ea6d998b047bc84c5c26013d50bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.56k/3.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/hexists/distilbert-base-uncased-finetuned-clinc\n",
      "   b39e8d7..eb4eaa5  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/hexists/distilbert-base-uncased-finetuned-clinc/commit/eb4eaa5f9506f5ecaa438d71e25ba618424ae3a1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer.push_to_hub(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bf2d7e0-d3fc-49e5-b9ba-a3ce8758f71c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetuned_ckpt = \"hexists/distilbert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=finetuned_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6268f929-e9a6-4653-8adb-39d65994af42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 크기 (MB) - 255.88\n",
      "평균 레이턴시 (ms) - 18.15 +\\- 1.07\n",
      "테스트 세트 정확도 - 0.859\n"
     ]
    }
   ],
   "source": [
    "optim_type = \"DistilBERT\"\n",
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84bc189b-eca9-4f2c-96a3-dd9a9253b49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/rtsz9nj93kdd9vy3_52zngfc0000gn/T/ipykernel_10254/1811107928.py:19: MatplotlibDeprecationWarning: The legendHandles attribute was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use legend_handles instead.\n",
      "  for handle in legend.legendHandles:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(perf_metrics, current_optim_type):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient='index')\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        # 현재 최적화 방법을 점선으로 그립니다\n",
    "        if idx == current_optim_type:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, \n",
    "                        alpha=0.5, s=df_opt[\"size_mb\"], label=idx, \n",
    "                        marker='$\\u25CC$')\n",
    "        else:\n",
    "            plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, \n",
    "                        s=df_opt[\"size_mb\"], label=idx, alpha=0.5)\n",
    "            \n",
    "    legend = plt.legend(bbox_to_anchor=(1,1))\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_sizes([20])\n",
    "\n",
    "    plt.ylim(80,90)\n",
    "    # 가장 느린 모델을 사용해 x 축 범위를 정합니다\n",
    "    xlim = int(perf_metrics[\"BERT baseline\"][\"time_avg_ms\"] + 3)\n",
    "    plt.xlim(1, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency (ms)\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c8ccda6-bffb-48fb-8962-9bd240f6651e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hp_space(trial):\n",
    "    return {\"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
    "        \"temperature\": trial.suggest_int(\"temperature\", 2, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7c54a-1e5e-4344-82fa-a54553131678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-26 22:15:16,195] A new study created in memory with name: no-name-00bfbdda-5c26-4570-ab99-1580d0e8ec6c\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2862/2862 54:52, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.204262</td>\n",
       "      <td>0.606452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.099008</td>\n",
       "      <td>0.841290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.065601</td>\n",
       "      <td>0.883548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.904516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>0.916452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.035782</td>\n",
       "      <td>0.917742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>0.922258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.920323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-26 23:10:10,813] Trial 0 finished with value: 0.9203225806451613 and parameters: {'num_train_epochs': 9, 'alpha': 0.74436928980191, 'temperature': 10}. Best is trial 0 with value: 0.9203225806451613.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 1:01:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.195369</td>\n",
       "      <td>0.599677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.095150</td>\n",
       "      <td>0.841613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>0.883226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.047140</td>\n",
       "      <td>0.902581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>0.915161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.034227</td>\n",
       "      <td>0.918387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.031051</td>\n",
       "      <td>0.921613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.029201</td>\n",
       "      <td>0.922903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.028202</td>\n",
       "      <td>0.925161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.027788</td>\n",
       "      <td>0.922581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 00:11:50,380] Trial 1 finished with value: 0.9225806451612903 and parameters: {'num_train_epochs': 10, 'alpha': 0.49237209362866596, 'temperature': 15}. Best is trial 1 with value: 0.9225806451612903.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2226/2226 42:47, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.425500</td>\n",
       "      <td>0.219138</td>\n",
       "      <td>0.610645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.835161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.071260</td>\n",
       "      <td>0.882581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.046066</td>\n",
       "      <td>0.910645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.042112</td>\n",
       "      <td>0.914516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.040872</td>\n",
       "      <td>0.914516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 00:54:39,944] Trial 2 finished with value: 0.9145161290322581 and parameters: {'num_train_epochs': 7, 'alpha': 0.432253135586808, 'temperature': 7}. Best is trial 1 with value: 0.9225806451612903.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2544/2544 48:45, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.196931</td>\n",
       "      <td>0.590968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>0.097680</td>\n",
       "      <td>0.834194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.066189</td>\n",
       "      <td>0.881935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.899677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.042566</td>\n",
       "      <td>0.911290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.916452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.916774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.035047</td>\n",
       "      <td>0.916129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 01:43:27,185] Trial 3 finished with value: 0.9161290322580645 and parameters: {'num_train_epochs': 8, 'alpha': 0.2847321259070802, 'temperature': 16}. Best is trial 1 with value: 0.9225806451612903.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2544/2544 48:52, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.195379</td>\n",
       "      <td>0.589355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.097191</td>\n",
       "      <td>0.832581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.066055</td>\n",
       "      <td>0.880323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.042571</td>\n",
       "      <td>0.911290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.038180</td>\n",
       "      <td>0.916129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.035902</td>\n",
       "      <td>0.916774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.035073</td>\n",
       "      <td>0.916129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 02:32:21,399] Trial 4 finished with value: 0.9161290322580645 and parameters: {'num_train_epochs': 8, 'alpha': 0.9341531662586628, 'temperature': 18}. Best is trial 1 with value: 0.9225806451612903.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2862/2862 54:43, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>0.233160</td>\n",
       "      <td>0.629032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.107079</td>\n",
       "      <td>0.843548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0.890645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.907097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.915806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.918387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>0.921290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.030748</td>\n",
       "      <td>0.923226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.030339</td>\n",
       "      <td>0.923871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 03:27:06,204] Trial 5 finished with value: 0.9238709677419354 and parameters: {'num_train_epochs': 9, 'alpha': 0.47251658607696045, 'temperature': 5}. Best is trial 5 with value: 0.9238709677419354.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 636/2226 12:08 < 30:26, 0.87 it/s, Epoch 2/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>0.605161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.105109</td>\n",
       "      <td>0.834839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 03:39:16,404] Trial 6 pruned. \n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 318/2862 06:05 < 49:02, 0.86 it/s, Epoch 1/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.200210</td>\n",
       "      <td>0.600323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 03:45:23,668] Trial 7 pruned. \n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 1:01:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.250210</td>\n",
       "      <td>0.642581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.109717</td>\n",
       "      <td>0.847419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>0.895484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.047292</td>\n",
       "      <td>0.908710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.038424</td>\n",
       "      <td>0.919032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.033505</td>\n",
       "      <td>0.921613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>0.927097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.028561</td>\n",
       "      <td>0.927742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>0.929032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>0.928387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 04:46:30,998] Trial 8 finished with value: 0.9283870967741935 and parameters: {'num_train_epochs': 10, 'alpha': 0.3781776765475281, 'temperature': 4}. Best is trial 8 with value: 0.9283870967741935.\n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2862/2862 54:46, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>0.233160</td>\n",
       "      <td>0.629032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.107079</td>\n",
       "      <td>0.843548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.067892</td>\n",
       "      <td>0.890645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.907097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.915806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.918387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.032353</td>\n",
       "      <td>0.921290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.030748</td>\n",
       "      <td>0.923226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.030339</td>\n",
       "      <td>0.923871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 05:41:19,432] Trial 9 pruned. \n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='636' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 636/1908 12:07 < 24:19, 0.87 it/s, Epoch 2/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.805200</td>\n",
       "      <td>0.422160</td>\n",
       "      <td>0.655484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.162847</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-27 05:53:28,665] Trial 10 pruned. \n",
      "/Users/daniellee/Develop/study_huggingface/.venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1087' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1087/3180 20:24 < 39:21, 0.89 it/s, Epoch 3.42/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798400</td>\n",
       "      <td>0.405471</td>\n",
       "      <td>0.664839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.140670</td>\n",
       "      <td>0.846774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>0.072805</td>\n",
       "      <td>0.900968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna \n",
    "\n",
    "best_run = distilbert_trainer.hyperparameter_search(\n",
    "    n_trials=20, direction=\"maximize\", hp_space=hp_space)\n",
    "\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d3454-9888-4ac4-8423-27ff1d0fd695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab72b5-758c-4815-8fed-371a10c83aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,v in best_run.hyperparameters.items():\n",
    "    setattr(student_training_args, k, v)\n",
    "    \n",
    "# 정제된 모델을 저장할 새로운 저장소를 정의합니다\n",
    "distilled_ckpt = \"distilbert-base-uncased-distilled-clinc\"\n",
    "student_training_args.output_dir = distilled_ckpt\n",
    "\n",
    "# 최적의 매개변수로 새로운 Trainer를 만듭니다\n",
    "distil_trainer = DistillationTrainer(model_init=student_init,\n",
    "    teacher_model=teacher_model, args=student_training_args,\n",
    "    train_dataset=clinc_enc['train'], eval_dataset=clinc_enc['validation'],\n",
    "    compute_metrics=compute_metrics, tokenizer=student_tokenizer)\n",
    "\n",
    "distil_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee61f29-341b-41e7-b155-d2c82742cd6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distil_trainer.push_to_hub(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2cd433-7ba2-4a70-8522-1e80d602ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `hexists`를 자신의 허브 사용자 이름으로 바꾸세요.\n",
    "distilled_ckpt = \"hexists/distilbert-base-uncased-distilled-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=distilled_ckpt)\n",
    "optim_type = \"Distillation\"\n",
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be4c62-b4ac-457a-8155-fb5a99be6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57958b58-6507-4007-b9d9-d701564766b2",
   "metadata": {},
   "source": [
    "### 8.4 양자화로 모델 속도 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccb44e-a336-4a0c-a26b-9d4e5eac161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "state_dict = pipe.model.state_dict()\n",
    "weights = state_dict[\"distilbert.transformer.layer.0.attention.out_lin.weight\"]\n",
    "plt.hist(weights.flatten().numpy(), bins=250, range=(-0.3,0.3), edgecolor=\"C0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac0da3-96b2-457e-87a0-6581169b8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point = 0\n",
    "scale = (weights.max() - weights.min()) / (127 - (-128))\n",
    "\n",
    "(weights / scale + zero_point).clamp(-128, 127).round().char()\n",
    "\n",
    "from torch import quantize_per_tensor\n",
    "\n",
    "dtype = torch.qint8\n",
    "quantized_weights = quantize_per_tensor(weights, scale, zero_point, dtype)\n",
    "quantized_weights.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02402f84-0f95-4fee-8fe0-d759e2f4e13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 트랜스포머 가중치에서 양자화 효과\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes,mark_inset\n",
    "\n",
    "# 히스토그램 그리기\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(quantized_weights.dequantize().flatten().numpy(), \n",
    "         bins=250, range=(-0.3,0.3), edgecolor=\"C0\");\n",
    "# 확대 그림 만들기\n",
    "axins = zoomed_inset_axes(ax, 5, loc='upper right')\n",
    "axins.hist(quantized_weights.dequantize().flatten().numpy(), \n",
    "         bins=250, range=(-0.3,0.3));\n",
    "x1, x2, y1, y2 = 0.05, 0.1, 500, 2500\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "axins.axes.xaxis.set_visible(False)\n",
    "axins.axes.yaxis.set_visible(False)\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d447d-f3fe-465a-b298-ec59e89fffa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "weights @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ea74b-2ab1-41e8-a4a9-9fd7f1497d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.quantized import QFunctional\n",
    "\n",
    "q_fn = QFunctional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235f8fd-59d9-49e2-9961-d208c909e446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "q_fn.mul(quantized_weights, quantized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beddf30-c11c-4ec9-beff-62c796960330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.getsizeof(weights.storage()) / sys.getsizeof(quantized_weights.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068a727-baf9-4eb2-84b3-72a783766531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import quantize_dynamic\n",
    "\n",
    "# `hexists`를 자신의 허브 사용자 이름으로 바꾸세요.\n",
    "model_ckpt = \"hexists/distilbert-base-uncased-distilled-clinc\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt).to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a1e70-201e-4abb-87cc-41bb0ec66848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'qnnpack'  # 실행이 안될때는 이렇게... https://stackoverflow.com/a/69996449\n",
    "model_quantized = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb66f34-85b9-464d-8abe-be50b9959556",
   "metadata": {},
   "source": [
    "### 8.5 양자화된 모델의 벤치마크 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f144ac-97ac-41a1-bf61-96e6c4ca58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model_quantized, \n",
    "                tokenizer=tokenizer)\n",
    "optim_type = \"Distillation + quantization\"\n",
    "pb = PerformanceBenchmark(pipe, clinc[\"test\"], optim_type=optim_type)\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849466ec-d2f0-4983-814c-d355cd840c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886bb27-c749-4af1-9237-95b5b3eafdf3",
   "metadata": {},
   "source": [
    "### 8.6 ONNX와 ONNX 런타임으로 추론 최적화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d83ce-9554-4ccc-8e9d-f6be0dacb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from psutil import cpu_count\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = f\"{cpu_count()}\"  # ONNX 런타입에서 병렬 계산에 사용할 스레드 개수\n",
    "os.environ[\"OMP_WAIT_POLICY\"] = \"ACTIVE\"  # 대기 스레드를 활성 상태로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d9b83-626d-4d49-a605-50a7204ee7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.convert_graph_to_onnx import convert\n",
    "\n",
    "# `hexists`를 자신의 허브 사용자 이름으로 바꾸세요.\n",
    "model_ckpt = \"hexists/distilbert-base-uncased-distilled-clinc\"\n",
    "onnx_model_path = Path(\"onnx/model.onnx\")\n",
    "convert(framework=\"pt\", model=model_ckpt, tokenizer=tokenizer, \n",
    "        output=onnx_model_path, opset=12, pipeline_name=\"text-classification\")\n",
    "#opset=12, ONNX는 변경 불가능한 연산 규격을 그룹화하기 위해 연산자 집합을 사용, ONNX 라이브러리의 특정 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7540962-2ff6-46d6-9a89-78f8a343cadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from onnxruntime import (GraphOptimizationLevel, InferenceSession, \n",
    "                         SessionOptions)\n",
    "\n",
    "def create_model_for_provider(model_path, provider=\"CPUExecutionProvider\"): \n",
    "    options = SessionOptions()\n",
    "    options.intra_op_num_threads = 1\n",
    "    options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    session = InferenceSession(str(model_path), options, providers=[provider])\n",
    "    session.disable_fallback()\n",
    "    return session\n",
    "\n",
    "onnx_model = create_model_for_provider(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261f440-f331-470a-aa21-a24659b44c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = clinc_enc[\"test\"][:1]\n",
    "del inputs[\"labels\"]\n",
    "logits_onnx = onnx_model.run(None, inputs)[0]\n",
    "logits_onnx.shape\n",
    "\n",
    "np.argmax(logits_onnx)\n",
    "clinc_enc[\"test\"][0][\"labels\"] # 정답 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a33f6-cf77-49d0-8fd4-8c5d59bd8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "class OnnxPipeline:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __call__(self, query):\n",
    "        model_inputs = self.tokenizer(query, return_tensors=\"pt\")\n",
    "        inputs_onnx = {k: v.cpu().detach().numpy() \n",
    "                       for k, v in model_inputs.items()}\n",
    "        logits = self.model.run(None, inputs_onnx)[0][0, :]\n",
    "        probs = softmax(logits)\n",
    "        pred_idx = np.argmax(probs).item()\n",
    "        return [{\"label\": intents.int2str(pred_idx), \"score\": probs[pred_idx]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e99f76-a17e-47ba-b5bf-d449292074c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = OnnxPipeline(onnx_model, tokenizer)\n",
    "pipe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f0b98-bfc1-4d82-a989-872eb4300817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxPerformanceBenchmark(PerformanceBenchmark):\n",
    "    def __init__(self, *args, model_path, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        \n",
    "    def compute_size(self):\n",
    "        size_mb = Path(self.model_path).stat().st_size / (1024 * 1024)\n",
    "        print(f\"모델 크기 (MB) - {size_mb:.2f}\")\n",
    "        return {\"size_mb\": size_mb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07596d1f-96d2-4465-b8b8-41ea7804db11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim_type = \"Distillation + ORT\"\n",
    "pb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type,\n",
    "                              model_path=\"onnx/model.onnx\")\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfb2c6-3065-4d85-af82-df371ebe87e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_metrics(perf_metrics, optim_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f41d4-b43d-423b-a9b3-b311e146fce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_input = \"onnx/model.onnx\"\n",
    "model_output = \"onnx/model.quant.onnx\"\n",
    "quantize_dynamic(model_input, model_output, weight_type=QuantType.QInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be8135-5300-4af5-b44f-b0e59c757ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onnx_quantized_model = create_model_for_provider(model_output)\n",
    "pipe = OnnxPipeline(onnx_quantized_model, tokenizer)\n",
    "optim_type = \"Distillation + ORT (quantized)\"\n",
    "pb = OnnxPerformanceBenchmark(pipe, clinc[\"test\"], optim_type, \n",
    "                              model_path=model_output)\n",
    "perf_metrics.update(pb.run_benchmark())\n",
    "\n",
    "plot_metrics(perf_metrics, optim_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
